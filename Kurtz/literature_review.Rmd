---
title: "State of the Literature - March 2022"
author: "Emily Kurtz"
date: "3/6/2022"
fontsize: 12pt
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Process

We have been working with data from 2015 to present. I decided to get a sense of the literature that has been published in the latter end of that time frame, so I have been searching for articles from 2017 or after. I started my search in Google Scholar, searching for related keywords like "SEC EDGAR," "10-K," "filings," etc. I refined by date.

I paid attention initially to abstracts and methods/data sections. If the article seemed relevant, I began to read more thoroughly. I have not read through everything yet, but I have so far identified 10 useful articles. I plan to add more and read through the chosen ones in more detail.

## Run EDGAR Run: SEC Dissemination in a High-Frequency World - Rogers, Skinner, and Zechman

### Summary and Importance

Accoding to the SEC's homepage, "the SEC protects investors, promotes fairness in the securities markets, and shares information about companies and investment professionals to help investors make informed decisions and invest with confidence" (https://www.sec.gov/). One obligation in the pursuit of fairness is that the SEC make filings "publicly available." The release of filings has a financial impact on the market; trades occur and prices change as a result of the information in the filings. Thus, access to the information in the filings can give investors and advantage.

This is no problem if all investors are on equal footing, and indeed making this information publicly available helps achieve this goal. However, as of the publishing of this article, "the majority of filings [were] available to paying subscribers of the SEC's public dissemination system (PDS) feed before they [were] posted to the EDGAR website, and so provide[d] subscribers and thier clients with a private advantage." This advantage was economically significant and the article showed that the market responds to information contained in the filings before they are even posted to EDGAR. These results caused the SEC to launch an investigation and to eliminate the PDS advantage.

### Methods

The researchers use data from March 2012 through December 2013. They obtain Form 4 filings from Thomson-Reuters. The article uses some standard statistical tools, like OLS and Wilcoxon rank sum tests. There doesn't seem to be anything particularly unusual statistically.

## The Pessimism Factor: SEC EDGAR Form 10-K Textual Analysis and Stock Returns - Chouliaras

### Summary and Importance

This paper studies the impact that pessimism plays on stock behavior. Previous literature has explored this idea and found that negative (pessimism) percentage itself does not play a significant role in future stock returns. But this paper finds that the change in pessimism over time, along with how a stock previously performed, does play a significant role.

More specifically, the pessimism percentage (a metric which is defined in the Methods section of this paper) is not significant when measuring returns for a filing during the month that the filing is submitted. However, the change in pessimism from the previous year to the current year is significant in mearuing the returns in the month when the filing is submitted. The coefficient is negative, meaning a positive change in pessimism (i.e. more negative words used in the filing in the current year compared to the previous year) leads to lower returns in the submission month compared the the previous year. 

The distinction is important. It seems to make sense that more negativity in a filing would lead to lower returns, but previous research was not able to empirically show this. This paper shows that the change from the previous year, and increased negativity as compared to previous years, not just the raw negativity overall, is what is really significant.

### Methods

The paper uses a Python webcrawler to access SEC 10-K data files. It looks at the years from 1992 to 2015. It cleans the files. The reseacher measures the positive percentage of words by dividing the number of positive words by the total number of words for each 10-K filing. They remove stop words from the denominator. They repeat this same process for negative words, and obtain a Pessimism metric for each filing, which is defined as the difference between the proportion of words that are negative and the proportion that are positive. To that point, the Pessimism metric is negative if the filing contains a higher proportion of positive words than negative words, and is positive if the filing contains a higher proportion of negative words than positive words. Positive pessimism scores signify overall net negativitiy, and vice versa.

To find that the change in pessimism is significant, as discussed in the previous section, the researcher uses a linear regression model. The variable of interest is the interaction between change in pessimism and returns from the previous year (i.e. showing that the current year's returns change significantly with changes in the interaction between the previous year's returns and the change in pessimism between the two years). I wonder if some sort of time series analysis might have been more straightforward here.

## edgar: An R package for the U.S. SEC EDGAR retrieval and parsing of corporate filings - Lonare, Patil, and Raut

### Summary and Importance

This paper was published quite recently (December 2021). It summarizes the functions of an R package that downloads and analyzes the SEC public disclosures. It "facilitates downloading, parsing, searching, and sentiment analysis of corporate reports," so it probably would be a good aid to the type of work that a lot of these recent articles have done/perhaps future work for this project.

The name of the package is "edgar." It has 12 total functions.

### Methods

I'll discuss the functions in more detail here. However, it might also be useful, if interested, to just dive into the help manual.

```{r}
#install.packages("edgar")
library(edgar)
```

Here is a summary of the functions:

\begin{table}[!htbp]
\begin{tabular}{ll}
get8KItems         & Retrieves Form 8-K event information                   \\
getBusinDescr      & Retrieves business descriptions from annual statements \\
getDailyMaster     & Retrieves daily master index                           \\
getFilingHeader    & Scrape EDGAR filing header information                 \\
getFilingInfo      & Retrieves filing information of a firm                 \\
getFilings         & Retrieves EDGAR filings from SEC server                \\
getFilingsHTML     & Get HTML view of EDGAR filings                         \\
getMasterIndex     & Retrieves quarterly master index                       \\
getMgmtDisc        & Retrieves management's discussion and analysis section \\
getSentiment       & Provides sentiment measures of EDGAR filings           \\
LMMasterDictionary & Loughran and McDonald Sentiment Master Dictionary      \\
searchFilings      & Search EDGAR filings for specific keywords            
\end{tabular}
\end{table}

It seems getFilingInfo() is the function that does essentially what I did last semester (i.e. gets all of the 10-K filings). The paper itself references quarterly returns, as does the help text, so that is expected to match up exactly with what I was collecting. The package also has cleaning functions and a handful of NLP functions.



## OpenEDGAR: Open Source Software for SEC EDGAR Analysis - Bommarito, Katz, and Detterman

### Summary and Importance

This is similar to the last article, but it is presenting a Python package for EDGAR analysis, not an R package. Its main motivation is, perhaps unsurprisingly, to make using SEC data easier, given it is a legal requirement that companies share this data and it is within the spirit of the law to make it equitably accessible. The paper says the library was built on the Django application framework (I am not sure this is useful information since I am unfamiliar with that, but I figured I'd add it here anyways since it was apparently important enough to include in the abstract). It retrieves and parses filings abd creates tables for the most important data, among some other useful functionalities.

### Methods

The paper goes into decent detail about coding processes and practices. Those discussions seem more targeted to someone with more experience with Python and/or more of a computer science background than I have; if they are of interest, they're in section 2, which is on pages 2 and 3. The remainder of the paper talks about how the data set is built, stored, and accessed using the library.

## Do Retail Investors Use SEC Filings? Evidence from EDGAR Search - Chi and Shanthikumar

### Summary and Importance

### Methods

## A New Variable in Corporate Disclosure Analysis: An AI Study of the SEC EDGAR Database - Aldridge and Li

### Summary and Importance

### Methods

## The Effects of Information Acquisition in M&As: Evidence from SEC EDGAR Web Traffic - Wang

### Summary and Importance

### Methods

## EDGAR-CORPUS: Billions of Tokens Make The World Go Round - Loukas, Fergadiotis, Androutsopoulos, and Malakasiotis

### Summary and Importance

Potentially a great new package to deal with this data! - https://github.com/nlpaueb/edgar-crawler

### Methods

## The Interplay between Information Acquisition and Information Integration: Evidence from SEC 10-K/10-Q Filing Dates - Coyne, Kim, and Kim

### Summary and Importance

### Methods

## FinBERT: pre-trained model on SEC filings for financial natural language tasks - DeSola, Hanna, and Nonis

### Summary and Importance

### Methods



## Future Directions?

After scouring the web for recent work using SEC EDGAR, I had some idea for future work, if you change paths in this project. The first is to somehow see if the increased focus on access to SEC data in the past few years has made a difference in who uses the data, who is making trades, etc. Unfortunately, this idea can't "simply" be executed using SEC data like the project has in the past. It would require outside data, and I'm not sure where/how/if such data exists and can be found. But, a few of the articles touched upon equity and accessibility being the motivation for the papers, and it also seems to really fit in with the idea of "data science for the public good," so I think such a project, if possible to carry out, would be fulfilling and make a big splash.
