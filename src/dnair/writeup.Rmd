---
title: "Parsing SEC Filings to Identify Product Innovation: Working Document"
output:
  html_document: default
---

```{r libraries, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE, results = "hide"}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, error = FALSE, message = FALSE, results = "asis")
library(readr)
library(dplyr)
library(stringr)
library(xml2)
library(rvest)
library(stringr)
library(hunspell)
library(data.table)
library(htmltools)
library(magrittr)
library(htmltidy)
library(ggplot2)
library(wesanderson)
```

```{r functions}

remove_doc_types <- function(xml_string, types = c("GRAPHIC", "EXCEL", "ZIP", "EX-10.3", "EX-10.6", "EX-10.20")) {
  no_ns <- gsub("\\n", " ", xml_string)
  #browser()
  for (t in types) {
    find_str <- paste0("<DOCUMENT> ?<TYPE> ?", t)
    search_str <- paste0("<DOCUMENT> ?<TYPE> ?", t, ".*?</DOCUMENT>")
    found <-
      as.data.table(stringr::str_locate_all(no_ns, find_str))

    for (i in 1:nrow(found)) {
      locs <- as.data.table(stringr::str_locate(no_ns, search_str))
      st <- locs[1, start] - 1
      en <- locs[1, end] + 1
      ifelse(is.na(locs$start) == TRUE & is.na(locs$end) == TRUE, no_ns,
             no_ns <- paste0(substr(no_ns, 1, st), substr(no_ns, en, nchar(no_ns))) )
    }
  }
  no_ns
}

```

```{r ingestfiles, results = "hide"}
paths_file <- "~/git/business_innovation/data/business_innovation/original/edgar_filings/ALL_SEC_files.txt"
file_headers <- readr::read_tsv(paths_file, col_names = FALSE)
paths <- paste0("~/git/business_innovation/data/business_innovation/original/edgar_filings/Edgar_filings_folders/", file_headers$X1)
file_names <- unique(list.files(paths, full.names = TRUE))

wordcounts_1_1000 <- read_csv("~/git/business_innovation/data/business_innovation/working/sec/wordcounts_1_1000.csv")
wordcounts_1001_2000 <- read_csv("~/git/business_innovation/data/business_innovation/working/sec/wordcounts_1001_2000.csv")
wordcounts_2000_2867 <- read_csv("~/git/business_innovation/data/business_innovation/working/sec/wordcounts_2000_2867.csv")
allwordcounts <- as.data.table(rbind(wordcounts_1_1000, wordcounts_2000_2867, wordcounts_2000_2867))

ciknames <- read_rds("~/git/business_innovation/data/business_innovation/original/ciks_names.RDS")
sic <- read_rds("~/git/business_innovation/data/business_innovation/original/sic.download.RDS")
cik_ticker <- read_delim("~/git/business_innovation/data/business_innovation/original/edgar_filings/cik_ticker.csv", delim = "|")   #RANKANDFILE website
cikcountries <- read_delim("~/git/business_innovation/data/business_innovation/original/edgar_filings/edgar_state_country.csv", delim = "|") #RANKANDFILE website

allwords <- read_csv("~/git/business_innovation/data/business_innovation/working/sec/all_secwordlists.csv")
allregwords <- read_csv("~/git/business_innovation/data/business_innovation/working/sec/all_secregwordlists.csv")

colnames(sic) <- c("CIK", "SIC_CompName", "SIC_SIC", "SIC_Industry", "SIC_Location")
colnames(ciknames) <- c("CIK", "SEC_CompName", "SEC_SIC")
colnames(cik_ticker) <- c("CIK", "Ticker_TickerCode", "Ticker_CompName", "Ticker_Exchange", "Ticker_SIC", "Ticker_Location", "Ticker_Inc_Location", "Ticker_IRS")
colnames(cikcountries) <- c("Code", "Ticker_StateCountry")
```

```{r datatypes , results = "hide"}
sic$SIC_SIC <- as.numeric(sic$SIC_SIC)
sic$CIK <- as.numeric(sic$CIK)
ciknames$CIK <- as.numeric(ciknames$CIK)
ciknames$SEC_SIC <- as.numeric(ciknames$SEC_SIC)
#incorp <- cik_ticker %>% select(CIK, Incorporated)
```

```{r reshape data, results = "hide"}
wcbycomp <- reshape2::dcast(allwordcounts, Company + Words ~ Year, value.var = "count", fun.aggregate = sum)
wcbyword <- reshape2::dcast(allwordcounts, Words + Company ~ Year, value.var = "count", fun.aggregate = sum)
wcbycompdetails <- wcbycomp %>%
  left_join(ciknames, by = c("Company" = "CIK")) %>%
  left_join(sic, by = c("Company" = "CIK", "SEC_SIC" = "SIC_SIC")) %>%
  left_join(cik_ticker, by = c("Company" = "CIK"))

```

```{r datarowshaping, results = "hide"}
length(file_names)
length(unique(ciknames$cik))  # 779 - total # of companies classified as pharm/med device by SEC 

patt1 <- "(?<=Edgar_filings_folders/)(.*)(?=.txt)"
patt2 <- "(?<=/)(.*)(?=_10-K_)"
orig_companies <- str_extract(str_extract((file_names), patt1), patt2)
length(unique(orig_companies)) #703 companies with filings

length(unique(wcbycomp$Company)) # 365 - # of companies that we found non-English words in their filings

orig_companies <- as.numeric(orig_companies)
orig_companies <- as.data.frame(orig_companies)

origcomp_details <- orig_companies %>%
  filter(!is.na(orig_companies)) %>% 
  unique() %>% 
  left_join(ciknames, by = c("orig_companies" = "CIK")) %>%
  left_join(sic, by = c("orig_companies" = "CIK", "SEC_SIC" = "SIC_SIC")) %>%
  left_join(cik_ticker, by = c("orig_companies" = "CIK"))

#saveRDS(origcomp_details, "~/git/business_innovation/data/business_innovation/working/sec/origcomp_details.RDS")

```

### Introduction

This project aims to test the feasibility to identify, measure, and characterize product innovation using non-survey data sources. Our goal is to develop methods to complement and enhance the BRDIS survey that collects information from a representative set of companies and asks whether they have introduced a new product to the market. Specifically, we are developing text-based methods to be applied to administrative (e.g., financial filings) and opportunity data (e.g., trade journals, press releases) to determine:

* whether a company has launched a new product?
* how many new products are introduced?
* what are the features of the new product(s)?
* how that innovation trends over time?

To answer these questions, we measure innovation in terms of products, and seek to capture a new product and characterize its trajectory across a number of text based sources. Additionally, we focus on the pharmaceutical and medical device industry that are highly regulated such that new products require approval from the Food and Drug Administration (FDA). We make the assumption that the FDA approval dataset (which is publicly available) is the universal set of all new products, and ask what the portion of these products we can capture using administrative and opportunity data. Their respective SIC codes are given here. 

```{r}
knitr::kable(tibble("SIC" = unique(origcomp_details$SEC_SIC),
       "Industry" = unique(origcomp_details$SIC_Industry)) %>% filter(!is.na(SIC)))
```

We chose to focus on the pharmaceutical and medical device industry because of the strictly regulated process of launching new products that is specific to this industry. Consider the following as a high-level illustration of the process a new drug or medical device might take to the market:

1. Research & Development: Company undertakes research to develop, test, and trial new device and drug. 
2. FDA Application: Company submits application to FDA for device or drug approval.
3. Approval Announcements: FDA releases announcements to the public. 
4. Press Activity: Media outlets report on the announcements, company and competitor relationships, and launches to market.
5. Market Activity: Company retails device or drug.
6. Financial Reports: Company submits financial reports to US Securities & Exchange Commission (SEC). 

```{r}
# class(origcomp_details)
# origcomp_details$Industry <- subset.data.frame(x = origcomp_details, select = 8)
compcount1 <- origcomp_details %>% 
    group_by(SIC_Industry) %>%
    summarise(no_companies = n())

compcount2 <- ciknames %>% 
  left_join(sic, by = c("CIK", "SEC_SIC" = "SIC_SIC")) %>% 
  group_by(SIC_Industry) %>%
  summarise(no_companies = n())

compcount3 <- allwordcounts %>% 
  group_by(Company, Year) %>% 
  summarise(count = n())

```

By tracing products through their lifecycle from FDA approval through financial impact, we can expand upon the BRDIS survey results by providing additional context and information around what innovation looks like in the pharmaceutical industry. Furthermore, we can illustrate a process by which innovation can be uncovered and measured, at least in a highly regulated environment. 

### Data Source: SEC Filings

This portion of the research focused on the last stage of the lifecycle: whether a new product appears in the financial activities of a company. For this we used the SEC's EDGAR database of 10-K filings. Using the criteria of the two industries of interest, we identified `r length(unique(ciknames$cik))` companies in their database as belonging to the pharmaceutical/medical device industries. Of these, `r nrow(unique(orig_companies))` filed 10-K forms with the SEC, which report on their financial well-being as a company. 


Table below summarizes the number of companies on Edgar.

Company Sets | N
------------- | -------------
Total Number of Pharma Companies on Edgar | `r length(unique(ciknames$CIK))`
SIC 2834: Drugs| `r as.integer(compcount2["1",2]) `
SIC 3841: Devices | `r as.integer(compcount2["2",2]) `
Number Pharma Companies w 10-K| `r nrow(unique(orig_companies))`
SIC 2834: Drugs| `r as.integer(compcount1["2",2]) `
SIC 3841: Devices | `r as.integer(compcount1["3",2]) `

We collected the 10-K filings of the `r nrow(unique(orig_companies))` companies for the years 2013 -- 2016, which makes a total of `r length(file_names)` filings. 

### Approaches

Given the 10-K filing of a company, our goal is to identify mentions of product launches for a given year. This requires identifying product names in these filings, and finding those that are mentioned as being launched in the respective year. Currently, we are developing two parallel approaches which will be combined eventually. The first one involves obtaining non-English words in a filing and identifying those that are used in close "proximity" with our keywords of innovation, i.e., launch, new product (list to be expanded). Among the `r length(file_names)` filings, `r nrow(compcount3) ` referenced non-English words in their filings. The second approach is to identify names that are used with a trademark or a registered trademark sign.


#### Approach 1. Identifying Non-English Words to Capture Product Names

Below we describe our iterative process using one of the filings as an example.

Filings Sets | N
------------- | -------------
Total 10-K Filings  | `r length(file_names)`
10-K Filings w non-English | `r nrow(compcount3) `


##### Step 1: Ingest the text of an SEC filing

First the text of all filings was ingested, such that each text element represented an observation of the dataset. An example SEC filing can be found here: https://www.sec.gov/Archives/edgar/data/310158/000119312512084319/d274705d10k.htm.

Here's the text using the above linked Merck filing as an example. 

```{r}
url <- "https://www.sec.gov/Archives/edgar/data/310158/000119312512084319/d274705d10k.htm"
edgar <- read_html(remove_doc_types(read_file(url)))
paragraphs <- edgar %>% 
  xml_find_all( ".//p") %>% 
  html_text() %>%
  str_squish

print(head(paragraphs[dataplumbr::is_blank(paragraphs) == FALSE], 15))
```

##### Step 2: Filter text elements of significant length

There were `r length(paragraphs)` text elements overall in this filing. For each of these text elements, we selected only those elements that were at least 20 characters. This reduces the example by `r length(paragraphs) - length(paragraphs[nchar(paragraphs)>20])` to `r length(paragraphs[nchar(paragraphs)>20])`. 

```{r}
print(head(paragraphs[nchar(paragraphs)>20], 15))
```

##### Step 3: Filter text elements for key words

We then wanted to identify text elements that contained our target innovation phrases, so we looked for elements that contained the phrase "launch" or "new product." As you can see, it looks like the keyword "launch" identified a product called "Zetia."

```{r}
word_innov <- c("launch", "new product")
innov_text <- which(grepl(paste(word_innov, collapse = "|"), tolower(paragraphs)) == TRUE)

print(paragraphs[innov_text][11])
```

##### Step 4: Filter text elements for non-English words

Next, we wanted to determine the number and names of the new products mentioned in paragraphs containing "launch" or new product, so we looked for any non-English words in these text elements. We do see "Zetia" in this list! 

```{r}
knitr::kable(allwordcounts[Company == 310158][1:5])
```

##### Step 5: Filtering out non-English words 

5.1. Company Names

We observe that the list of non-English words that we have obtained from the filings can also include (i) company names or (ii) sector-specific terms. Therefore,  dictionaries for these groups need to be generated to identify and eliminate them. 
 
To the extent possible, we want to remove any cases where the non-English word used is actually a company. So we use our list of companies in the SEC database, the original set of `r nrow(unique(orig_companies)) ` companies. For cases where a company is named, rather than a product, we hope to find a way to flag that mention as a mention of 'self' or 'competitor.'

```{r}
colnames(origcomp_details) <- c("CIK Code", "CIK Company Name", "SIC Code", "SIC Company Name", "SIC Industry", "SIC Location", "Ticker Incorporation Location")
knitr::kable(origcomp_details[31:36,c(1,2)]) #,5,6,7)])
```

Steps to identify and clean these names will include:

* tokenizing
* transforming to lower case
* stemming words (eg. from 'sciences' to 'science')
* identifying and separating English words (eg. 'pharmaceutical' or 'sciences')
* identifying and separating common business naming tokens (eg. 'inc' or 'holdings')

5.2. Mentions in Multiple Companies' Filings

Moreover, we observe that some of these drugs are products of their competitors', hence their names will appear in filings of multiple companies. In order to address this, we look at the names across companies, and filter out those that appear in multiple companies' filings.  

```{r}
dis <- wcbyword %>% filter(Words == "Adderall")

knitr::kable(dis)
```

We will consider these drugs appearing in multiple companies' filings separately from uniquely-mentioned drug.

##### Step 6: Arrange data over time 

In this step we will summarize the drug names by company by year, helping us to count mentions of new products for each company over time. 

```{r}
merck <- data.table::as.data.table(wcbycompdetails)[SEC_CompName == "Merck   Co  Inc , Merck   Co   Inc ",]
knitr::kable(merck[1, 9:14])
knitr::kable(merck %>% tail(4))
```

### Resulting Dataset


```{r}
# counts of unique product mentions by company
comps <- wcbycompdetails %>% group_by(SIC_CompName, SIC_Industry) %>% summarise(count = n())   %>% arrange(desc(count)) 
pharm_comps <- comps %>% filter(SIC_Industry == "PHARMACEUTICAL PREPARATIONS")
device_comps <- comps %>% filter(SIC_Industry == "SURGICAL & MEDICAL INSTRUMENTS & APPARATUS")
comps_top <- comps %>% arrange(desc(count)) %>% head(30)

pal_ind <- wes_palette("Zissou1", 2, type = "discrete")

customPlot = list(
  theme(#plot.margin = unit(c(1,1,2,2), "cm"),
        axis.text.x  = element_text(vjust=0.5, size=12),
        plot.title=element_text(size=12, vjust=2),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        panel.background = element_rect(fill = "#FFFFFF"), 
        legend.position="bottom"),
  coord_flip()
  , guides(fill=guide_legend(title="Key"))
)

ggplot(data=(pharm_comps %>% arrange(desc(count)) %>% head(50)), 
       aes(x=reorder(SIC_CompName, count), y=count, fill = factor(SIC_Industry))) +
  geom_bar( stat="identity") +
  scale_fill_manual(values = pal_ind[1]) + 
  customPlot

ggplot(data=device_comps %>% arrange(desc(count)) %>% head(50), 
       aes(x=reorder(SIC_CompName, count), y=count, fill = factor(SIC_Industry))) +
  geom_bar( stat="identity") +
  scale_fill_manual(values = pal_ind[2]) + 
  customPlot

ggplot(data=comps_top, aes(x=reorder(SIC_CompName, count), y=count, fill = factor(SIC_Industry))) +
    geom_bar( stat="identity") + 
  scale_fill_manual(values = pal_ind) +
  customPlot + 
  labs(title = "Top Companies Across Industries", 
      y = "Number of Products (All Time)",
      x = "Companies")

```


```{r}
usa_sum <- wcbycompdetails %>% 
  group_by(Ticker_Location, SIC_Industry) %>% 
  summarise(count = n()) %>% 
  left_join(cikcountries, by = c("Ticker_Location" = "Code")) %>%
  filter(Ticker_Location %in% c("CA", "CO", "CT", "DC", "FL", "GA", "IL",  "IN", "MA", "MD", "MI", "MN", "MO", "NC", "NC", "NH",  "NJ", "NV", "NY", "OH", "PA", "SC", "TN", "TX", "UT", "WA"))

ggplot(data=usa_sum, aes(x=reorder(Ticker_StateCountry, count), y=count, fill = factor(SIC_Industry))) +
    geom_bar( stat="identity") +
  scale_fill_manual(values = pal_ind) +
  customPlot

'%ni%' <- Negate('%in%')

countries_sum <- wcbycompdetails %>% 
  group_by(SIC_Location, SIC_Industry) %>% 
  summarise(count = n()) %>% 
  left_join(cikcountries, by = c("SIC_Location" = "Code")) %>%
  filter(SIC_Location %ni% c("CA", "CO", "CT", "DC", "FL", "GA", "IL",  "IN", "MA", "MD", "MI", "MN", "MO", "NC", "NC", "NH",  "NJ", "NV", "NY", "OH", "PA", "SC", "TN", "TX", "UT", "WA"))

ggplot(data=countries_sum, aes(x=reorder(Ticker_StateCountry, count), y=count, fill = factor(SIC_Industry))) +
    geom_bar( stat="identity") + 
  scale_fill_manual(values = pal_ind) +
  customPlot
```

```{r}
# counts of unique product mentions by company
names(allwordcounts)
names(origcomp_details)
#tme_summ <- allwordcounts %>% left_join(origcomp_details, by = c("Company" = "orig_companies")) # %>% group_by(Year, SIC_Industry) %>% summarise(count = n()) 
#wcbycompdetails %>% group_by(SIC_Industry, `2012`, `2013`, `2014`, `2015`, `2016`, `2017` ) %>% summarise(count = n()) %>% select(-count) %>% melt(id.vars = "SIC_Industry")

time_summ <- allwordcounts %>%
  left_join(ciknames, by = c("Company" = "CIK")) %>% 
  left_join(sic, by = c("Company" = "CIK", "SEC_SIC" = "SIC_SIC")) %>%
  left_join(cik_ticker, by = c("Company" = "CIK")) %>%
  group_by(SIC_Industry, Year) %>%
  summarise(count = n())

ggplot(data = time_summ, aes(x=Year, y=count, group=SIC_Industry, colour = SIC_Industry)) + 
    geom_line(linetype="dashed", size=1.5) + 
    geom_point(size=4, shape=21, fill="white")
```


```{r}
drugsbytime <- allwordcounts %>% group_by(Words, Year) %>% 
  summarise(count = n()) %>% 
  dcast(Words ~ Year, value.var = "count", fun.aggregate = sum) %>% 
  mutate(sum = `2012`+`2013`+`2014`+`2015`+`2016`+`2017`)  %>% arrange(desc(sum)) 

drugsbytime_top <- drugsbytime %>% 
  head(10) %>% 
  select(-sum) %>% 
  melt(id=c("Words"), variable.name = "Year")

ggplot(data = drugsbytime_top, aes(x=Year, y=value, group = Words, colour = Words)) + 
    geom_line(linetype="dashed", size=1.5) + 
    geom_point(size=4, shape=21, fill="white")

```


```{r}
#wcbycompdetails %>% select(Words, `2012`,`2013`,`2014`,`2015`,`2016`,`2017`, SIC_CompName, Ticker_Exchange)

exchange_products <- wcbycompdetails %>% 
  group_by(`2012`,`2013`,`2014`,`2015`,`2016`,`2017`, Ticker_Exchange) %>% 
  summarise(count = n()) %>% 
  melt(id = "Ticker_Exchange")  %>% 
  group_by(Ticker_Exchange, variable) %>% 
  summarise(sum = sum(value)) %>%
  filter(variable != "count")

colnames(exchange_products) <- c("Exchange", "Year", "Products")

ggplot(data = exchange_products, aes(x=Year, y=Products, group = Exchange, colour = Exchange)) + 
    geom_line(linetype="dashed", size=1.5) + 
    geom_point(size=4, shape=21, fill="white")

```





##### Final Step: Count Products By Company
TBD

### Next Steps

As illustrated above, there is still much work to do with the data simply within the SEC filings. In addition to the phases listed below, we hope to dig deeper into competitive relationships at play. 

#### Approach 2: Identifying Registered & Trademarked Tokens
For example, we hope to add a column to indicate whether the identified word has a "Registered" or "Trademarked" symbol adjacent to it. Below, you can see some registered and trademarked tokens we hope to match to our existing word list. 

```{r}
head(unique(allregwords$Words), 10)
```

