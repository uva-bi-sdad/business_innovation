---
title: "Text Method on SEC Filings - Cleaning Wordlist Results"
output: html_document
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(stringr)
library(dplyr)
library(corpus)
```

```{r functions}
stem_hunspell <- function(term) {
  # look up the term in the dictionary
  stems <- hunspell::hunspell_stem(term)[[1]]

  if (length(stems) == 0) { # if there are no stems, use the original term
    stem <- term
  } else { # if there are multiple stems, use the last one
    stem <- stems[[length(stems)]]
  }

  stem
}

'%!in%' <- function(x,y)!('%in%'(x,y))
```

Loading: 

* non-English words from SEC 10K filings
* any word with R or TM at end
* list of all companies (SIC-SEC-Ticker)

```{r load_data}
allwordcounts <- readRDS("~/git/business_innovation/data/working/sec/allnonenglishwordcounts.RDS")
regwords <- read_csv("~/git/business_innovation/data/working/sec/all_secregwordlists.csv")
companylist <- readRDS("~/git/business_innovation/data/working/sec/companylist.RDS")
```

```{r loaddata}
#allwordcounts <- read_csv("~/git/business_innovation/data/working/sec/all_secwordlists.csv")
wcbycompdetails <- readRDS("~/git/business_innovation/data/working/sec/fuzzymatching/2_wcbycompdetails.RDS")
#nonEnglishwords_detectedascompanies <- readRDS("~/git/business_innovation/data/working/sec/fuzzymatching/4_tokencompanyrefset.RDS")

#wcbycompdetails_compcheck %>% select(Token, SEC_Company_Name, Self, Comp) %>% filter( Comp > 0 )
regwords <- read_csv("~/git/business_innovation/data/working/sec/all_secregwordlists.csv")
company_list <- readRDS("~/git/business_innovation/data/working/sec/companylist_secsictick.RDS")
```

Manipulate data:

* "pivot" words to move years from rows into columns
* find distinct companies in original list
* create column that concatenates all name strings across CIK codes

Note: 5,679 word-mentions

```{r shaping_data}
wcbywordcomp <- reshape2::dcast(allwordcounts, Words + Company ~ Year, sum) #wcbyword <- reshape2::dcast(allwordcounts, Words ~ Year, sum)
company_reference_names <- companylist %>% distinct() %>% 
  mutate(CompanyString = paste(SIC_Company_Name, SEC_Company_Name, Ticker_Company_Name)) 
```

Create two 'dictionaries':

* company name stop words ex. inc, corp
* pharma stop words ex. biopharma, therapeutics

```{r}
stopwords <- as.vector(c("inc", "corp", "ltd","plc","llc","hold?ing?s","international","group","acquisition","american","china","usa"))
pharmstopwords <- c("biopharma", "therapeutics?", "pharmaceuticals?", "international", "sciences?", "medical", "technology", "phrma", "pharma", "bio", "biosciences?")

stopwords <- paste0( stopwords, collapse = "|")
pharmstopwords <- paste0(paste0("\\b", pharmstopwords, "\\b"), collapse = "|")
```

Create company name reference set: 

* new columns 
    - tokens of company names
    - tokens as lower case
    - stemmed tokens 
* remove tokens less than a character long
* rename columns to indicate source of each name

```{r}
comp_tokens <- str_split(company_reference_names$CompanyString, pattern = " |[[:punct:]]")

new_ref_companies <- tibble(company_reference_names$CompanyString, comp_tokens) %>% # head() %>% 
  tidyr::unnest() %>% filter(nchar(comp_tokens) >1) %>% as.data.frame() %>%
  left_join(company_reference_names, by = c("company_reference_names$CompanyString" = "CompanyString")) %>%
  mutate(comp_lowword = str_to_lower(str_squish(comp_tokens))) %>% filter(comp_lowword %!in% stopwords) %>% 
  mutate(comp_low_hun = text_tokens(comp_lowword, stemmer = stem_hunspell)) %>% tidyr::unnest() %>% distinct()

head(new_ref_companies)
colnames(new_ref_companies) <- c("CompanyString", "Tokens", "CIK", "SIC_Company_Name", "SIC_SIC", "SIC_Industry", "SIC_Location", "SEC_Company_Name", "SEC_SIC", "Ticker_Code", "Ticker_Company_Name", "Ticker_Exchange", "Ticker_SIC_Code", "Ticker_Location", "Ticker_IncLoc", "Ticker_IRS", "token_low", "token_hun")
```

Manipulate company set: 

* find English tokens that repeat 
* remove tokens that repeat 

Consequence: you lose any names that are only composed of generic pharma names: ex. Drugs Pharmaceuticals Inc. would be lost

```{r}
multenglishtokens <- new_ref_companies %>% mutate(eng = hunspell::hunspell_check(token_hun)) %>% filter(eng == "TRUE") %>% group_by(token_hun) %>% summarise(n = n()) %>% filter(n > 1)

multtokens <- new_ref_companies %>% group_by(Tokens) %>% summarise(n = n()) %>% filter(n > 1)
new_ref_companies2 <- new_ref_companies
new_ref_companies <- new_ref_companies %>% filter(Tokens %!in% multtokens$Tokens)
```

Companies in Wordlist?

* generate regex patterns of company name tokens
    - original token
    - lower case token
    - stemmed token
* generate corresponding columns of wordlist
    - lower case word
* detect and extract company name tokens in wordlist

```{r}
patt = paste0("^", new_ref_companies$Tokens, "$", collapse = "|")
pattlow = paste0("^", new_ref_companies$token_low, "$", collapse = "|")
patthun = paste0("^", new_ref_companies$token_hun, "$", collapse = "|")

wcbyword_findcompanies <- wcbywordcomp %>% mutate(
  word_low = str_to_lower(Words),
  companyTF = str_detect(Words, patt), 
  compmatch = str_extract(Words, patt), 
  complowTF = str_detect(word_low, pattlow),
  complowmatch = str_extract(word_low, patthun))

```

Results: 

* 13% company tokens, found using original token 
    - 5007 word-mentions are candidate products
    - 672 word-mentions are company tokens
* 22% company tokens, found using lowcase token
    - 4634 word mentions are candidate products
    - 1045 word-mentions are company tokens

```{r}
table(wcbyword_findcompanies$companyTF) # 3650 FALSE, 197 TRUe
table(wcbyword_findcompanies$complowTF) # 3401 FALSE, 446 TRUe
```

Join wordlist w company v. cand products to ORIGINAL CIK so you have the name of the company that submitting that filing

```{r}
wcbyword_findcompanies %>% select(Words, Company, compmatch, complowmatch)
submittingcompanies <- companylist %>% select(CIK, SIC_Company_Name)
wcbyword_findcompanies <- wcbyword_findcompanies %>% inner_join(submittingcompanies, by = c("Company" = "CIK"))
colnames(wcbyword_findcompanies) <- c("Words", "SubmittingCIK", "Y2012", "Y2013", "Y2014", "Y2015", "Y2016", "Y2017",
                                      "Words_Low", "CompanyTF", "CompMatch", "CompLowTF", "CompLowMatch", "SubmittingCompany")

wcbyword_findcompanies <- wcbyword_findcompanies %>% 
  select(SubmittingCIK, SubmittingCompany, Words, Words_Low, CompMatch, CompLowMatch, Y2012, Y2013, Y2014, Y2015, Y2016, Y2017) %>%
  arrange(Words)
```

Create list of registered and trademarked brands, join to wordlist

```{r cars}
regwords2 <- regwords %>% mutate(Brand = str_remove(Words, "[®|™]"), 
                                 Symbol = str_extract(Words, "[®|™]"),
                                 Protection = ifelse(Symbol == "®", "R", 
                                                     ifelse(Symbol == "™", "T", "N")))

brands <- regwords2 %>% select(Brand, Protection) %>% distinct()

wcbyword_findcompanies <- wcbyword_findcompanies %>% left_join(brands, by = c("Words" = "Brand"))
```

Results: 

* 4605 word-mentions NOT protected brands - 80%
* 1016 word-mentions are REGISTERED brands - 17%
* 102 word-mentions are TRADEMARKED bradns - 1.7%

```{r}
table(wcbyword_findcompanies$Protection)
sum(is.na(wcbyword_findcompanies$Protection))
```

Overlap? 

* 5723 word mentions total

Company token matched set:

* 1047 total 
* 1006 not protected - 96%
* 41 protected - 3.9%
    - 39 R - 3.7% of all - 95% of protected
    - 2 TM - 0.0% of all - 4% of protected

Candidate products:

* 4676 total 
* 3599 not protected - 76%
* 1077 protected - 23%
    - 977 R - 20% of all - 90% of protected
    - 100 TM - 21% of all - 9 % of protected

```{r}
```

If Company - Self v Other? 

```{r}
wcbyword_findcompanies <- wcbyword_findcompanies %>% 
  mutate(SelfFlag1 = as.numeric(mapply(grepl, Words, SubmittingCompany)),
         SelfFlag2 = as.numeric(mapply(grepl, Words_Low, str_to_lower(SubmittingCompany))),
         SelfFlag = SelfFlag1 + SelfFlag2,
         SelfOther = ifelse(is.na(CompLowMatch),"PossProd", ifelse(SelfFlag > 0, "CompSelf", "CompOther" ))) 
```

Results: 

* 4676 Possible Products
* 932 word mentions - Companies talking about other companies
* 115 word mentions - Companies talking about themselves

```{r}
table(wcbyword_findcompanies$SelfOther)

```

```{r}
finalset <- wcbyword_findcompanies %>% select(SubmittingCompany, Words, Y2012, Y2013, Y2014, Y2015, Y2016, Y2017, Protection, SelfOther)
# saveRDS(finalset, "~/git/business_innovation/data/final/SEC/candidateproduct.RDS")
# write.csv(finalset, "~/git/business_innovation/data/final/SEC/candidateproduct.csv", row.names = FALSE)
```


To do later - check words for ending in TM or space letter R? may need to go back to original ALL words list 
